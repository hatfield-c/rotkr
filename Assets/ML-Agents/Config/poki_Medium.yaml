behaviors:
  poki_Agent:
    trainer_type: ppo
    hyperparameters:
      #batch_size: 2500
      #buffer_size: 45000
      batch_size: 1000
      buffer_size: 10000

      learning_rate: 0.0003

      beta: 0.009
      epsilon: 0.1
      lambd: 0.925

      num_epoch: 4
      learning_rate_schedule: linear

    keep_checkpoints: 5
    max_steps: 10000000
    time_horizon: 516
    summary_freq: 50000
    threaded: true

    network_settings:
      #normalize: true
      hidden_units: 64
      num_layers: 3
      vis_encode_type: simple

    reward_signals:

#      curiosity:
#        strength: 0.1
#        gamma: 0.9
#        encoding_size: 128

      extrinsic:
        gamma: 0.995
        strength: 1.0

#      gail:
#        demo_path: C:\Users\Cody\Documents\Unity\rotkr\Assets\ML-Agents\Demonstrations\it0speed.demo
#        strength: 0.05
#        gamma: 0.75
#        encoding_size: 128

#    behavioral_cloning:
#        demo_path: C:\Users\Cody\Documents\Unity\rotkr\Assets\ML-Agents\Demonstrations\it0speed.demo
#        strength: 0.05
#        steps: 750000
   
# end reward when collide, but make sure the cumulative reward is capped at -1 by looking at current punishment